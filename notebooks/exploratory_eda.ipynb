{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from nltk import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/IMDBSentimentData.csv'\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv()\n",
    "df = pd.read_csv(DATA_PATH, sep=',', header=0, names=['Review', 'Sentiment'])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb16856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame Info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0efd7",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- Total 50K reviews.\n",
    "- No missing values.\n",
    "- Both reviews and sentiment are str type object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cc177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame Description\n",
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf80061a",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- Most reviews are unique. \n",
    "- Two classes sentiment 'positive' and 'negative' -> Binary Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9dbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Distribution\n",
    "df['Sentiment'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46dab35",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- Both sentiment distribution are same, balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffe2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Value \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d296cb6",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d97b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review length\n",
    "df['Review_Length'] = df['Review'].apply(lambda x: len(x.split()))\n",
    "df['Review_Length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6275640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df['Review_Length'], bins=50, kde=True)\n",
    "plt.title('Review Length Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1d885",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- Most reviews are short to medium in length (around 173â€“280 units), but a few very long reviews (like 2470) pull the average higher than the median. \n",
    "\n",
    "- This indicates the data is right-skewed (a long tail of very lengthy reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Sentiment', y='Review_Length', data=df)\n",
    "plt.title('Length by Sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173eaf1f",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- Positive reviews contain most of the outlier compared to negative reviews. It could be that people who liked the movie expressed them very much.\n",
    "\n",
    "- After all observation, for a sweet spot, 128 token size could be nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00232b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Clouds (inform: common words suggest BoW/TF-IDF for ML)\n",
    "# Combine all positive and negative reviews\n",
    "positive = ' '.join(df[df['Sentiment'] == 'positive']['Review'])\n",
    "negative = ' '.join(df[df['Sentiment'] == 'negative']['Review'])\n",
    "\n",
    "# Generate word clouds\n",
    "wc_pos = WordCloud(width=800, height=400, background_color='white').generate(positive)\n",
    "wc_neg = WordCloud(width=800, height=400, background_color='black', colormap='Reds').generate(negative)\n",
    "\n",
    "# Plot side by side\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "# Positive\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(wc_pos, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Positive Reviews\")\n",
    "\n",
    "# Negative\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(wc_neg, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Negative Reviews\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-grams (inform: sequences suggest RNN/LSTM for context)\n",
    "def get_ngrams(text, n=2, top_k=10):\n",
    "    return Counter(ngrams(text.split(), n)).most_common(top_k)\n",
    "\n",
    "get_ngrams(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f35d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngrams(negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4872e61",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- Common stop words dominate, TF-IDF should work well for ML baselines.\n",
    "- N-grams show context, indicate LSTM will work well over simple ML."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imdb-movie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
